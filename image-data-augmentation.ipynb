{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1_W-aFFzLBM8"
      },
      "source": [
        "# Edge Impulse Image Data Augmentation Workshop\n",
        "\n",
        "[![Open In Colab <](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/edgeimpulse/workshop-image-data-augmentation/blob/main/image-data-augmentation.ipynb)\n",
        "\n",
        "This notebook is part of the Edge Impulse image data augmentation workshop. It downloads a simple image dataset (electronic components), transforms the images to create a series of augmented samples, and then uploads the augmented to your Edge Impulse project.\n",
        "\n",
        "Create a new project on [Edge Impulse](https://edgeimpulse.com/). Go to the dashboard of that project and copy your API key. Paste that key into the string value for `EI_API_KEY`. The final cell of this script will automatically upload the augmented dataset to your Edge Impulse project.\n",
        "\n",
        "Press **shift + enter** to execute each cell.\n",
        "\n",
        "Look for `***YOUR CODE HERE***` to write your own code for the challenges.\n",
        "\n",
        "Each output file will be the original filename appended with \"_{num}\" where {num} is some incrementing value based on the total number of transforms performed per image. For example, if you have a file named `alpha.0.png`, it will become `alpha.0_0.png`. The first transform will be `alpha.0_1.png`, the second transform will be `alpha.0_2.png` and so on.\n",
        "\n",
        "Author: EdgeImpulse, Inc.<br>\n",
        "Date: May 17, 2023<br>\n",
        "License: [Apache-2.0](apache.org/licenses/LICENSE-2.0)<br>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kevNX-ihhJsN"
      },
      "source": [
        "## Install dependencies, define settings, download original dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbfRAzb-jY-t"
      },
      "outputs": [],
      "source": [
        "# Update Node.js to the latest stable version (use '!' to call Linux commands)\n",
        "!npm cache clean -f\n",
        "!npm install -g n\n",
        "!n 16.18.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8PaNo5YerBh"
      },
      "outputs": [],
      "source": [
        "# Install the Edge Impulsen CLI tool\n",
        "!npm install -g --unsafe-perm edge-impulse-cli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMSS42ieeuGW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import shutil\n",
        "import PIL\n",
        "\n",
        "import skimage.transform\n",
        "import skimage.util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1YN6ryEev8r"
      },
      "outputs": [],
      "source": [
        "# ***YOUR CODE HERE***\n",
        "\n",
        "# Part 1\n",
        "# ---\n",
        "# Create a new Edge Impules project\n",
        "# Go to Edge Impulse > your_project > Dashboard > Keys\n",
        "# Copy API Key here\n",
        "EI_API_KEY = \"ei_706f...\" \n",
        "\n",
        "# ***END CODE***\n",
        "\n",
        "# Path information\n",
        "DATASET_NAME = \"electronic-components-png-original\"\n",
        "DATASET_URL = \"https://github.com/edgeimpulse/workshop-image-data-augmentation/raw/main/\" + DATASET_NAME + \".zip\"\n",
        "HOME_PATH = \"/content\"                  # Location of the working directory\n",
        "DATASET_ZIP = os.path.join(HOME_PATH, DATASET_NAME + \".zip\")\n",
        "DATASET_PATH = os.path.join(HOME_PATH, DATASET_NAME)\n",
        "OUT_NAME = \"augmented-dataset\"          # Name of output dataset folder and .zip file\n",
        "OUT_PATH = os.path.join(HOME_PATH, OUT_NAME)\n",
        "OUT_ZIP = OUT_PATH + \".zip\"\n",
        "\n",
        "# How to split the dataset\n",
        "TEST_RATIO = 0.2      # 20% reserved for test set, rest is for training\n",
        "\n",
        "# Max batch size for uploading to Edge Impulse\n",
        "MAX_UPLOAD_BATCH_SIZE = 100\n",
        "\n",
        "# You are welcome to change the seed to get different augmentation effects\n",
        "SEED = 42\n",
        "random.seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB-Nb5r-fRcU"
      },
      "outputs": [],
      "source": [
        "# Download and unzip the original dataset\n",
        "!wget {DATASET_URL}\n",
        "!mkdir {DATASET_PATH}\n",
        "!unzip -q -d {DATASET_PATH} {DATASET_ZIP}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ufEfXtmLgkLX"
      },
      "source": [
        "## Transformation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ujNvstYf6Yw"
      },
      "outputs": [],
      "source": [
        "def create_flipped(img):\n",
        "  \"\"\"\n",
        "  Generate 3 flipped versions of the original image: left-right flip, up-down\n",
        "  flip, and left-right and up-down flip.\n",
        "  \n",
        "  Args:\n",
        "      img: Original image as a Numpy array\n",
        "\n",
        "  Returns:\n",
        "      List of images as Numpy arrays\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a list of flipped images\n",
        "  flipped = []\n",
        "  flipped.append(np.fliplr(img))\n",
        "  flipped.append(np.flipud(img))\n",
        "  flipped.append(np.flipud(np.fliplr(img)))\n",
        "\n",
        "  return flipped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGDO7NCegp0L"
      },
      "outputs": [],
      "source": [
        "def create_rotated(img, rotations):\n",
        "  \"\"\"\n",
        "  Generates a number of rotated images as specified by the `rotations` argument.\n",
        "  \n",
        "  Args:\n",
        "      img: Original image as a Numpy array\n",
        "      rotations: List of rotations to perform (between 0 and 360 degrees)\n",
        "\n",
        "  Returns:\n",
        "      List of images as Numpy arrays\n",
        "  \"\"\"\n",
        "\n",
        "  # Create list of rotated images (keep 8-bit values)\n",
        "  rotated = []\n",
        "  for rot in rotations:\n",
        "    img_rot = skimage.transform.rotate(img, angle=rot, mode='edge', preserve_range=True)\n",
        "    img_rot = img_rot.astype(np.uint8)\n",
        "    rotated.append(img_rot)\n",
        "\n",
        "  return rotated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXe8Do5ygqwS"
      },
      "outputs": [],
      "source": [
        "def create_random_zooms(img, scale_factor, num_crops):\n",
        "  \"\"\"\n",
        "  Zoom by scaling the image by `scale_factor` amount. Perform a number of random\n",
        "  crops on that scaled image given be `num_crops`.\n",
        "\n",
        "  Args:\n",
        "      img: Original image as a Numpy array\n",
        "      scale_factor: Amount to zoom the original image (1.0 keeps the image size)\n",
        "      num_crops: Number of random crops to perform on the scaled image\n",
        "  Returns:\n",
        "      List of images as Numpy arrays\n",
        "  \"\"\"\n",
        "\n",
        "  # Only support zoom-in for now\n",
        "  if scale_factor < 1.0:\n",
        "    raise NotImplementedError(\"Scale factor must be >=1.0. Only zoom-in supported.\")\n",
        "\n",
        "  # Get height and width of original image\n",
        "  height = img.shape[0]\n",
        "  width = img.shape[1]\n",
        "\n",
        "  # Create scaled images (e.g. make the image bigger) and keep 8-bit values\n",
        "  if len(img.shape) == 2:    # Grayscale\n",
        "    channel_axis = None\n",
        "  elif len(img.shape) == 3:  # RGB (assume WHC)\n",
        "    channel_axis = 2\n",
        "  else:\n",
        "      raise IndexError(\"Only arrays with 2 and 3 dimensions are supported\")\n",
        "  img_scaled = skimage.transform.rescale(img, \n",
        "                                        scale=scale_factor, \n",
        "                                        anti_aliasing=True, \n",
        "                                        channel_axis=channel_axis,\n",
        "                                        preserve_range=True)\n",
        "  img_scaled = img_scaled.astype(np.uint8)\n",
        "\n",
        "  # Get height and width of scaled image\n",
        "  s_h = img_scaled.shape[0]\n",
        "  s_w = img_scaled.shape[1]\n",
        "\n",
        "  # Create list of random zooms\n",
        "  zooms = []\n",
        "  for i in range(num_crops):\n",
        "    \n",
        "    # Randomly choose start of crop point\n",
        "    crop_y = round(random.random() * (s_h - height))\n",
        "    crop_x = round(random.random() * (s_w - width))\n",
        "\n",
        "    # Crop scaled image\n",
        "    if len(img_scaled.shape) == 2:    # Grayscale\n",
        "      zoom = img_scaled[crop_y:(crop_y + height), crop_x:(crop_x + width)]\n",
        "    elif len(img_scaled.shape) == 3:  # RGB\n",
        "      zoom = img_scaled[crop_y:(crop_y + height), crop_x:(crop_x + width), :]\n",
        "    else:\n",
        "      raise IndexError(\"Only arrays with 2 and 3 dimensions are supported\")\n",
        "\n",
        "    # Append zoomed image to list\n",
        "    zooms.append(zoom)\n",
        "\n",
        "  return zooms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16seEHJCgsEz"
      },
      "outputs": [],
      "source": [
        "def create_random_translations(img, num_translations):\n",
        "  \"\"\"\n",
        "  Generate `num_translations` number of random translations of the original\n",
        "  image. Each translations is no more than 1/4 of the width or height of the \n",
        "  original image. New pixels are created by copying the pixels on the edge of\n",
        "  the original image.\n",
        "\n",
        "  Args:\n",
        "      img: Original image as a Numpy array\n",
        "      num_translations: Number of translations to perform (integer)\n",
        "  Returns:\n",
        "      List of images as Numpy arrays\n",
        "  \"\"\"\n",
        "\n",
        "  # Get height and width of original image\n",
        "  height = img.shape[0]\n",
        "  width = img.shape[1]\n",
        "\n",
        "  # Create list of random translations\n",
        "  translations = []\n",
        "  for i in range(num_translations):\n",
        "  \n",
        "    # Choose random amount to translate (up to 1/4 image width, height) in either direction\n",
        "    tr_y = round((0.5 - random.random()) * (height / 2))\n",
        "    tr_x = round((0.5 - random.random()) * (width / 2))\n",
        "\n",
        "    # Perform translation to create new image\n",
        "    translation = skimage.transform.AffineTransform(translation=(tr_y, tr_x))\n",
        "    img_tr = skimage.transform.warp(img, translation, mode='edge', preserve_range=True)\n",
        "    img_tr = img_tr.astype(np.uint8)\n",
        "\n",
        "    # Append translated image to list\n",
        "    translations.append(img_tr)\n",
        "\n",
        "  return translations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFhcbXDAgtTD"
      },
      "outputs": [],
      "source": [
        "def create_noisy(img, types):\n",
        "  \"\"\"\n",
        "  Generate images with noise added to the original. The types of supported noise\n",
        "  can be found here: \n",
        "  https://scikit-image.org/docs/stable/api/skimage.util.html#random-noise\n",
        "\n",
        "  Args:\n",
        "      img: Original image as a Numpy array\n",
        "      types: List of strings with desired types of noise to add\n",
        "  Returns:\n",
        "      List of images as Numpy arrays\n",
        "  \"\"\"\n",
        "\n",
        "  # Add noise of different types\n",
        "  noisy_imgs = []\n",
        "  for t in types:\n",
        "    noise = skimage.util.random_noise(img, mode=t, seed=None)\n",
        "    noise = (noise * 255).astype(np.uint8)\n",
        "    noisy_imgs.append(noise)\n",
        "\n",
        "  return noisy_imgs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "m50ZRozfg9mc"
      },
      "source": [
        "## Demonstrate transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9kbNTehg9Mh"
      },
      "outputs": [],
      "source": [
        "# Choose an original image for the demonstration\n",
        "original_path = \"/content/electronic-components-png-original/capacitor.00bff939.png\"\n",
        "\n",
        "# Open the image and convert it to a Numpy array\n",
        "img = PIL.Image.open(original_path)\n",
        "img_array = np.asarray(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d51aPGbwq9H3"
      },
      "outputs": [],
      "source": [
        "def show_images(imgs, cmap=None, figsize=(12, 12)):\n",
        "  \"\"\"\n",
        "  Use Matplotlib to show several images.\n",
        "\n",
        "  Args:\n",
        "      imgs: list of Numpy arrays to plot\n",
        "      cmap\n",
        "      figsize (optional): size of the indivisual plots\n",
        "  \"\"\"\n",
        "  figs, axs = plt.subplots(1, len(imgs), figsize=figsize)\n",
        "  for i in range(len(imgs)):\n",
        "    axs[i]. imshow(imgs[i], cmap=cmap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT8bqoYAguXK"
      },
      "outputs": [],
      "source": [
        "# Generate flipped versions of the image\n",
        "aug_imgs = create_flipped(img_array)\n",
        "show_images([img_array] + aug_imgs, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQGsmZzIi8w6"
      },
      "outputs": [],
      "source": [
        "# Generate flipped versions of the image\n",
        "aug_imgs = create_rotated(img_array, [45, 90, 135])\n",
        "show_images([img_array] + aug_imgs, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oS-as5Yqlk5F"
      },
      "outputs": [],
      "source": [
        "# Generate zoomed/cropped versions of the image\n",
        "aug_imgs = create_random_zooms(img_array, 1.5, 3)\n",
        "show_images([img_array] + aug_imgs, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2bX9Djwl2cC"
      },
      "outputs": [],
      "source": [
        "# Generate random translations\n",
        "aug_imgs = create_random_translations(img_array, 3)\n",
        "show_images([img_array] + aug_imgs, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiNcgHUDpc-D"
      },
      "outputs": [],
      "source": [
        "# Generate images with random noise added\n",
        "aug_imgs = create_noisy(img_array, ('gaussian', 'poisson', 's&p'))\n",
        "show_images([img_array] + aug_imgs, cmap='gray')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "01PvV43U23Rk"
      },
      "source": [
        "## Perform transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSjS2S31qlyn"
      },
      "outputs": [],
      "source": [
        "# Delete output directory (if it exists) and recreate it\n",
        "if os.path.exists(OUT_PATH):\n",
        "  shutil.rmtree(OUT_PATH)\n",
        "os.makedirs(OUT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BH00PPdD27Uo"
      },
      "outputs": [],
      "source": [
        "def create_transforms(file_path):\n",
        "  \"\"\"\n",
        "  Open image given by `file_path` and perform augmentation on that one image.\n",
        "\n",
        "  Args:\n",
        "      file_path: path to image\n",
        "\n",
        "  Returns:\n",
        "      List of images as Numpy arrays\n",
        "  \"\"\"\n",
        "\n",
        "  # Open the image\n",
        "  img = PIL.Image.open(file_path)\n",
        "\n",
        "  # Convert the image to a Numpy array (keep all color channels)\n",
        "  img_array = np.asarray(img)\n",
        "\n",
        "  # Add original image to front of list\n",
        "  aug_imgs = []\n",
        "  aug_imgs.append([img_array])\n",
        "\n",
        "  # Perform transforms\n",
        "  aug_imgs.append(create_flipped(img_array))\n",
        "  aug_imgs.append(create_flipped(img_array))\n",
        "  aug_imgs.append(create_rotated(img_array, [45, 90, 135]))\n",
        "  aug_imgs.append(create_random_zooms(img_array, 1.3, 2))\n",
        "\n",
        "  # ***YOUR CODE HERE***\n",
        "  \n",
        "  # Part 2\n",
        "  # ---\n",
        "  # Call the `create_random_translations()` and `create_noisy()` functions with\n",
        "  # the original image and append the results to `aug_imgs` as shown in the \n",
        "  # example transforms above. Create 3 random translation and 3 noisy augmented\n",
        "  # images.\n",
        "  \n",
        "\n",
        "\n",
        "  # ***END CODE***\n",
        "\n",
        "  # ***YOUR CODE HERE***\n",
        "\n",
        "  # Part 3 (Optional challenge)\n",
        "  # ---\n",
        "  # Call more than one transformation function on a single image to generate\n",
        "  # compound augmentations.\n",
        "\n",
        "  \n",
        "\n",
        "  # ***END CODE***\n",
        "\n",
        "  # Flatten list of lists (to create one long list of images)\n",
        "  aug_imgs = [img for img_list in aug_imgs for img in img_list]\n",
        "\n",
        "  return aug_imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgUeJQlF3NRq"
      },
      "outputs": [],
      "source": [
        "# Go through each original image file in the unzipped directory\n",
        "for filename in os.listdir(DATASET_PATH):\n",
        "\n",
        "  # Skip the Jupyter Notebook checkpoints folder that sometimes gets added\n",
        "  if filename == \".ipynb_checkpoints\":\n",
        "    continue\n",
        "\n",
        "  # Parse the filename into label and unique ID\n",
        "  file_root, file_ext = os.path.splitext(filename)\n",
        "  label = file_root.split('.')[0]\n",
        "  uid = '.'.join(file_root.split('.')[1:])\n",
        "\n",
        "  # Do all transforms for that one image\n",
        "  file_path = os.path.join(DATASET_PATH, filename)\n",
        "  img_tfs = create_transforms(file_path)\n",
        "\n",
        "  # Save images to new files in output directory\n",
        "  for i, img in enumerate(img_tfs):\n",
        "\n",
        "    # Create a Pillow image from the Numpy array\n",
        "    img_pil = PIL.Image.fromarray(img)\n",
        "\n",
        "    # Construct filename (<original>_<transform_num>.<EXT>)\n",
        "    out_file_path = os.path.join(OUT_PATH, label + \".\" + uid + \"_\" + str(i) + file_ext)\n",
        "\n",
        "    # Convert Numpy array to image and save as a file\n",
        "    img_pil = PIL.Image.fromarray(img)\n",
        "    img_pil.save(out_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoA4TgOV38Kp"
      },
      "outputs": [],
      "source": [
        "# Zip the augmented dataset\n",
        "%cd {OUT_PATH}\n",
        "!zip -FS -r -q {OUT_ZIP} *\n",
        "%cd {HOME_PATH}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ywPoIp9S5kue"
      },
      "source": [
        "Feel free to download the *augmented-dataset.zip* file to have the dataset locally."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CDdoOyQr5vvu"
      },
      "source": [
        "## Upload Dataset to Edge Impulse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VozfQUOF5iMD"
      },
      "outputs": [],
      "source": [
        "# Create list of files for one category\n",
        "paths = []\n",
        "for filename in os.listdir(OUT_PATH):\n",
        "  paths.append(os.path.join(OUT_PATH, filename))\n",
        "\n",
        "# Shuffle and divide into test and training sets\n",
        "random.shuffle(paths)\n",
        "num_test_samples = int(TEST_RATIO * len(paths))\n",
        "test_paths = paths[:num_test_samples]\n",
        "train_paths = paths[num_test_samples:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziniFmN884eI"
      },
      "outputs": [],
      "source": [
        "# Upload training set to Edge Impulse in mini batches\n",
        "for first in range(0, len(train_paths), MAX_UPLOAD_BATCH_SIZE):\n",
        "\n",
        "  # Construct one long string with all the paths of the mini batch\n",
        "  train_mini_batch = train_paths[first:(first + MAX_UPLOAD_BATCH_SIZE)]\n",
        "  print(f\"Uploading {len(train_mini_batch)} files. Number {first} to \" \\\n",
        "        f\"{first + MAX_UPLOAD_BATCH_SIZE} out of a total of {len(train_paths)}.\")\n",
        "  train_mini_batch = ['\"' + s + '\"' for s in train_mini_batch]\n",
        "  train_mini_batch = ' '.join(train_mini_batch)\n",
        "\n",
        "  # Upload to Edge Impulse\n",
        "  !edge-impulse-uploader \\\n",
        "  --category training \\\n",
        "  --api-key {EI_API_KEY} \\\n",
        "  --silent \\\n",
        "  {train_mini_batch}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-M52uFBb54Bh"
      },
      "outputs": [],
      "source": [
        "# Upload test set to Edge Impulse in mini batches\n",
        "for first in range(0, len(test_paths), MAX_UPLOAD_BATCH_SIZE):\n",
        "\n",
        "  # Construct one long string with all the paths of the mini batch\n",
        "  test_mini_batch = test_paths[first:(first + MAX_UPLOAD_BATCH_SIZE)]\n",
        "  print(f\"Uploading {len(test_mini_batch)} files. Number {first} to \" \\\n",
        "        f\"{first + MAX_UPLOAD_BATCH_SIZE} out of a total of {len(test_paths)}.\")\n",
        "  test_mini_batch = ['\"' + s + '\"' for s in test_mini_batch]\n",
        "  test_mini_batch = ' '.join(test_mini_batch)\n",
        "\n",
        "  # Upload to Edge Impulse\n",
        "  !edge-impulse-uploader \\\n",
        "  --category testing \\\n",
        "  --api-key {EI_API_KEY} \\\n",
        "  --silent \\\n",
        "  {test_mini_batch}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
